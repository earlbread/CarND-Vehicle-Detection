{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle detection\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier\n",
    "* Optionally, you can also apply a color transform and append binned color features, as well as histograms of color, to your HOG feature vector. \n",
    "* Note: for those first two steps don't forget to normalize your features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use your trained classifier to search for vehicles in images.\n",
    "* Run your pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected.\n",
    "\n",
    "## Process Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the required modules and define the functions to proceed with each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_images(row, col, images, titles, h_pad=None, w_pad=None, fontsize=30):\n",
    "    fig, axes = plt.subplots(row, col, figsize=(15, 15))\n",
    "    fig.tight_layout(h_pad=h_pad)\n",
    "    \n",
    "    if row == 1 and col == 1:\n",
    "        axes.imshow(images[0], cmap='gray')\n",
    "        axes.set_title(titles[0], fontsize=fontsize)\n",
    "    elif row == 1:\n",
    "        idx = 0\n",
    "        for ax in axes:\n",
    "            ax.imshow(images[idx], cmap='gray')\n",
    "            ax.set_title(titles[idx], fontsize=fontsize)\n",
    "            idx += 1\n",
    "    else:\n",
    "        idx = 0\n",
    "        for axes_row in axes:\n",
    "            for ax in axes_row:\n",
    "                ax.imshow(images[idx], cmap='gray')\n",
    "                ax.set_title(titles[idx], fontsize=fontsize)\n",
    "                idx += 1\n",
    "                \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def get_random_image(images, rgb=True):\n",
    "    idx = random.randint(0, len(images))\n",
    "    image = cv2.imread(images[idx])\n",
    "    \n",
    "    if rgb:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract features and train classifier\n",
    "\n",
    "#### 1. Read all images data\n",
    "\n",
    "For this project, I used a labeled dataset for vehicle and non-vehicle to train my classifier. These example images come from a combination of the GTI vehicle image database, the KITTI vision benchmark suite, and examples extracted from the project video itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "car_images = glob.glob('./data/vehicles/**/*.png')\n",
    "notcar_images = glob.glob('./data/non-vehicles/**/*.png')\n",
    "\n",
    "num_of_car_images = len(car_images)\n",
    "num_of_notcar_images = len(notcar_images)\n",
    "\n",
    "print('Number of Car images = {}'.format(num_of_car_images))\n",
    "print('Number of Not-Car images = {}'.format(num_of_notcar_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "car = get_random_image(car_images)\n",
    "notcar = get_random_image(notcar_images)\n",
    "\n",
    "show_images(1, 2, [car, notcar], ['Car', 'Not-Car'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extract features\n",
    "\n",
    "I used color features, color of histogram features and HOG features. Below is the parameters to train my classifier and HOG features example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color_space = 'YCrCb'\n",
    "spatial_size = (16, 16)\n",
    "hist_bins = 32\n",
    "orient = 9\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = 'ALL'\n",
    "spatial_feat = True\n",
    "hist_feat = True\n",
    "hog_feat = True\n",
    "\n",
    "import feature\n",
    "\n",
    "car = get_random_image(car_images)\n",
    "notcar = get_random_image(notcar_images)\n",
    "\n",
    "car_y = cv2.cvtColor(car, cv2.COLOR_RGB2YCrCb)[:, :, 0]\n",
    "notcar_y = cv2.cvtColor(notcar, cv2.COLOR_RGB2YCrCb)[:, :, 0]\n",
    "\n",
    "hog, car_hog = feature.get_hog_features(car_y, orient, pix_per_cell, cell_per_block, vis=True)\n",
    "hog, notcar_hog = feature.get_hog_features(notcar_y, orient, pix_per_cell, cell_per_block, vis=True)\n",
    "\n",
    "show_images(1, 4,\n",
    "            [car_y, car_hog, notcar_y, notcar_hog,],\n",
    "            ['Car CH-1', 'Car Hog', 'Not-Car CH-1', 'Not-car Hog',],\n",
    "            h_pad=3.0,\n",
    "            fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Train classifier\n",
    "\n",
    "I chose Linear SVM as my classifier. To train my classifier I extracted features from data, scaled and trained them. After training I saved the model and parameters to use. The detailed code is in train.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Slide window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dist_pickle = pickle.load(open(\"./svc_pickle.p\", \"rb\" ))\n",
    "\n",
    "color_space = dist_pickle[\"color_space\"]\n",
    "svc = dist_pickle[\"svc\"]\n",
    "X_scaler = dist_pickle[\"scaler\"]\n",
    "orient = dist_pickle[\"orient\"]\n",
    "pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "spatial_size = dist_pickle[\"spatial_size\"]\n",
    "hog_channel = dist_pickle[\"hog_channel\"]\n",
    "hist_bins = dist_pickle[\"hist_bins\"]\n",
    "spatial_feat = dist_pickle[\"spatial_feat\"]\n",
    "hist_feat = dist_pickle[\"hist_feat\"]\n",
    "hog_feat = dist_pickle[\"hog_feat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I searched vehicle using multi-scale windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from search import slide_window, search_windows\n",
    "\n",
    "image = mpimg.imread('test_images/test7.jpg')\n",
    "windows_image = np.copy(image)\n",
    "x_start_stop = [None, None]\n",
    "xy_overlap = (0.75, 0.75)\n",
    "\n",
    "y_start_stops = [[400, 645],\n",
    "                 [400, 600],\n",
    "                 [400, 550]]\n",
    "xy_windows = [(128, 128),\n",
    "              (96, 96),\n",
    "              (64, 64)]\n",
    "\n",
    "windows = []\n",
    "\n",
    "for y_start_stop, xy_window in zip(y_start_stops, xy_windows):\n",
    "    windows.extend(slide_window(image, x_start_stop, y_start_stop, xy_window, xy_overlap))\n",
    "\n",
    "windows_image = draw_boxes(image, windows, color=(0, 0, 255), thick=6)                    \n",
    "show_images(1, 1, [windows_image], ['Windows'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I searched vehicles using search_windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from search import slide_window, search_windows\n",
    "\n",
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "draw_image = np.copy(image)\n",
    "\n",
    "image = image.astype(np.float32)/255\n",
    "\n",
    "x_start_stop = [None, None]\n",
    "xy_overlap = (0.5, 0.5)\n",
    "y_start_stops = [[400, 645],\n",
    "                 [400, 600],\n",
    "                 [400, 550]]\n",
    "xy_windows = [(128, 128),\n",
    "              (96, 96),\n",
    "              (64, 64)]\n",
    "\n",
    "windows = []\n",
    "\n",
    "for y_start_stop, xy_window in zip(y_start_stops, xy_windows):\n",
    "    windows.extend(slide_window(image, x_start_stop, y_start_stop, xy_window, xy_overlap))\n",
    "\n",
    "hot_windows = search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "\n",
    "window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "\n",
    "\n",
    "show_images(1, 1, [window_img], ['Detected'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove false positive and overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step, I removed false positives and some overlappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from search import slide_window, search_windows\n",
    "from heatmap import *\n",
    "\n",
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "draw_image = np.copy(image)\n",
    "\n",
    "image = image.astype(np.float32)/255\n",
    "\n",
    "x_start_stop = [None, None]\n",
    "xy_overlap = (0.5, 0.5)\n",
    "y_start_stops = [[400, 645],\n",
    "                 [400, 600],\n",
    "                 [400, 550]]\n",
    "xy_windows = [(128, 128),\n",
    "              (96, 96),\n",
    "              (64, 64)]\n",
    "\n",
    "windows = []\n",
    "\n",
    "for y_start_stop, xy_window in zip(y_start_stops, xy_windows):\n",
    "    windows.extend(slide_window(image, x_start_stop, y_start_stop, xy_window, xy_overlap))\n",
    "\n",
    "hot_windows = search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "\n",
    "window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "\n",
    "heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "heat = add_heat(heat, hot_windows)\n",
    "\n",
    "heat = apply_threshold(heat, 2)\n",
    "\n",
    "heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "labels = label(heatmap)\n",
    "draw_img = draw_labeled_bboxes(np.copy(draw_image), labels)\n",
    "\n",
    "\n",
    "\n",
    "show_images(1, 3, [window_img, heatmap, draw_img], ['Detected Window', 'Heatmap', 'Result'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result and Thoughts\n",
    "\n",
    "[![Result Video](http://img.youtube.com/vi/R2h0aC3q9Cc/0.jpg)](https://www.youtube.com/watch?v=R2h0aC3q9Cc)\n",
    "\n",
    "- It takes a lot of time to detect vehicle. I need to try another method like [YOLO](https://pjreddie.com/darknet/yolo/).\n",
    "\n",
    "- My detection boxes are really wobbly and does not fit to the vehicle. I will try to solve it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
